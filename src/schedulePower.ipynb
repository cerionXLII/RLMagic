{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import gymnasium as gym\n",
    "import pygame\n",
    "import random\n",
    "from collections import deque\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get device\n",
    "CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create environment\n",
    "The Schedule needs an environment, lets create it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a class for the schedule problem using the gym interface\n",
    "class ScheduleGym():\n",
    "    def __init__(self, num_days, num_hours, num_classes, num_subjects, verbose=False):\n",
    "        self.num_days = num_days\n",
    "        self.num_hours = num_hours\n",
    "        self.num_classes = num_classes\n",
    "        self.num_subjects = num_subjects\n",
    "        self.num_slots = num_days * num_hours\n",
    "        self.target_hours = np.zeros((num_classes, num_subjects), dtype=int) # Target hours for each class and subject\n",
    "        self.schedule = -1*np.ones((num_classes, num_days, num_hours), dtype=int) # Schedule for each class, -1 means no subject assigned\n",
    "        self.num_actions_left = 1000 #Number of actions left to take\n",
    "        self.verbose = verbose #Debug on or off\n",
    "        #This is to go from a one dimensional action space to a 4 dimensional action space\n",
    "        #class_id, day, hour, subject_id\n",
    "        self.max_values = np.array([num_classes, num_days, num_hours, num_subjects])\n",
    "        self.cumprod_max_values = np.cumprod(self.max_values[::-1])[::-1]\n",
    "        # self.decoder_base = np.cumprod(self.max_values)\n",
    "        # self.encoder_base = np.flip(np.cumprod(np.flip(self.max_values)))\n",
    "        self.initial_hours_to_assign = 0 #How many hours we have initially to assign, used to calculate score later\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        for class_id in range(self.num_classes):\n",
    "            for subject_id in range(self.num_subjects):\n",
    "                self.target_hours[class_id, subject_id] = np.random.randint(1, 5)\n",
    "        \n",
    "        self.initial_hours_to_assign = self.target_hours.sum().sum()\n",
    "\n",
    "        self.schedule = -1*np.ones((self.num_classes, self.num_days, self.num_hours), dtype=int) # Schedule for each class, -1 means no subject assigned\n",
    "        self.num_actions_left = self.initial_hours_to_assign * 10 #Optimally we would need to take number of hours to assign steps to complete the schedule, lets give it some wiggle room\n",
    "        \n",
    "        #Return the current state,info\n",
    "        info = {}\n",
    "        #return (self.target_hours, self.schedule), info\n",
    "        return self.state2vector(), info\n",
    "    \n",
    "    def state2vector(self):\n",
    "        #Convert the state to a vector\n",
    "        return np.concatenate([self.target_hours.flatten(), self.schedule.flatten()])/(self.initial_hours_to_assign * 10.0 + 1.0)\n",
    "    \n",
    "    def render(self):\n",
    "        #Print the schedule\n",
    "        for class_id in range(self.num_classes):\n",
    "            print(f\"Class {class_id + 1}:\")\n",
    "            for day in range(self.num_days):\n",
    "                print(f\"Day {day + 1}: {self.schedule[class_id, day]}\")\n",
    "            print()\n",
    "        print(f'Fitness: {self.fitness()}, Actions left: {self.num_actions_left}')\n",
    "\n",
    "        #print the target hours\n",
    "        print(\"Target Hours:\")\n",
    "        for class_id in range(self.num_classes):\n",
    "            print(f\"Class {class_id + 1}: {self.target_hours[class_id]}\")\n",
    "\n",
    "\n",
    "\n",
    "    def decode_action(self, actions):\n",
    "        actions = np.array(actions).reshape(-1) # Ensure numbers is a 1D column array\n",
    "        aAll = np.zeros((actions.shape[0], len(self.max_values)), dtype=int)\n",
    "        for i in range(len(self.max_values) - 1):\n",
    "            aAll[:, i] = actions // self.cumprod_max_values[i+1]\n",
    "            actions -= aAll[:, i]*self.cumprod_max_values[i+1]\n",
    "        aAll[:,-1] = actions\n",
    "        \n",
    "        return aAll\n",
    "    \n",
    "    # Go from a 4D action to a 1D action\n",
    "    def encode_action(self, actions):\n",
    "        number = np.zeros(actions.shape[0], dtype=int)\n",
    "        for i in range(len(self.max_values) - 1):\n",
    "            number += actions[:,i]*self.cumprod_max_values[i+1]\n",
    "        number += actions[:,-1]\n",
    "        \n",
    "        return number\n",
    "\n",
    "            \n",
    "    #next_state, reward, done, truncated, info = env.step(action)\n",
    "    # def step(self, action):\n",
    "    #     # Update the schedule based on the action\n",
    "\n",
    "    #     #Check if the action is a tuple or a single value\n",
    "    #     if isinstance(action, tuple):\n",
    "    #         #We are already in the decoded format\n",
    "    #         class_id, day, hour, subject_id = action\n",
    "    #     elif isinstance(action, np.ndarray):\n",
    "    #         class_id = action[0]\n",
    "    #         day = action[1]\n",
    "    #         hour= action[2]\n",
    "    #         subject_id = action[3]\n",
    "    #     else:\n",
    "    #         #Need to go from 1D to 4D\n",
    "    #         decoded = self.decode_action(action).squeeze()\n",
    "    #         class_id = decoded[0]\n",
    "    #         day = decoded[1]\n",
    "    #         hour= decoded[2]\n",
    "    #         subject_id = decoded[3]\n",
    "\n",
    "         \n",
    "    #     #If subject_id is >= num_subjects then this is a remove action for the class_id, day, hour slot\n",
    "    #     #If the slot is already occupied, then the old subject will be placed back into the target hours\n",
    "        \n",
    "    #     current_subject_id = self.schedule[class_id, day, hour]\n",
    "\n",
    "    #     if self.verbose:\n",
    "    #         print('Before action:')\n",
    "    #         for class_id in range(self.num_classes):\n",
    "    #             print(f\"Class {class_id + 1}: {self.target_hours[class_id]}\")\n",
    " \n",
    "    #     #The slot was already booked, lets reomove it (and all of its dependencies)\n",
    "    #     result = \"N/A\"\n",
    "    #     reward = 0\n",
    "    #     if current_subject_id != -1:\n",
    "    #         self.schedule[class_id, day, hour] = -1\n",
    "    #         self.target_hours[class_id, current_subject_id] += 1\n",
    "    #         result = \"Removed\"\n",
    "    #         reward = -0.16 #Penalty for removing a subject\n",
    "\n",
    "        \n",
    "    #     #See if it is an add action\n",
    "    #     elif subject_id < self.num_subjects:\n",
    "    #         #Yes its an add action, lets see if we have enough hours to actually add it\n",
    "    #         if self.target_hours[class_id, subject_id] > 0:\n",
    "    #             self.schedule[class_id, day, hour] = subject_id\n",
    "    #             self.target_hours[class_id, subject_id] -= 1\n",
    "    #             result = \"Added\"\n",
    "    #             reward = 0.15 #Reward for adding a subject\n",
    "    #         else:\n",
    "    #             #We are trying to add a subject that is already empty\n",
    "    #             reward = -0.25 #Penalty for invalid action    \n",
    "    #     else:\n",
    "    #         #We are trying to remove a subject that is not in the schedule, this is an invalid action\n",
    "    #         reward = -0.5 #Penalty for invalid action\n",
    "        \n",
    "    #     self.num_actions_left -= 1\n",
    "    #     done = self.is_done()  \n",
    "    #     if done:\n",
    "    #         reward += 1.0\n",
    "    #         reward += self.fitness()  #If we are done we get the full score of the schedule\n",
    "        \n",
    "    #     if self.verbose:\n",
    "    #         print(f\"Action: {action}, Class: {class_id}, Subject: {subject_id}, Day: {day}, Hour: {hour}, , current_subject_id: {current_subject_id}, Result: {result}, reward: {reward}, done: {done}\")     \n",
    "    #         print('After action:')\n",
    "    #         for class_id in range(self.num_classes):\n",
    "    #             print(f\"Class {class_id + 1}: {self.target_hours[class_id]}\")\n",
    "\n",
    "    #         if done:\n",
    "    #             print('Final schedule:')\n",
    "    #             self.render()\n",
    "                \n",
    "    #     truncated, info = False, {} #To be implemented later if needed\n",
    "    #     #Return the next state, reward, done, truncated and info\n",
    "    #     #return (self.target_hours, self.schedule), reward, done, truncated, info\n",
    "    #     return self.state2vector(), reward, done, truncated, info\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Update the schedule based on the action\n",
    "\n",
    "        #Check if the action is a tuple or a single value\n",
    "        if isinstance(action, tuple):\n",
    "            #We are already in the decoded format\n",
    "            class_id, day, hour, subject_id = action\n",
    "        elif isinstance(action, np.ndarray):\n",
    "            class_id = action[0]\n",
    "            day = action[1]\n",
    "            hour= action[2]\n",
    "            subject_id = action[3]\n",
    "        else:\n",
    "            #Need to go from 1D to 4D\n",
    "            decoded = self.decode_action(action).squeeze()\n",
    "            class_id = decoded[0]\n",
    "            day = decoded[1]\n",
    "            hour= decoded[2]\n",
    "            subject_id = decoded[3]\n",
    "\n",
    "         \n",
    "        #If subject_id is >= num_subjects then this is a remove action for the class_id, day, hour slot\n",
    "        #If the slot is already occupied, then the old subject will be placed back into the target hours\n",
    "        \n",
    "        current_subject_id = self.schedule[class_id, day, hour]\n",
    "\n",
    "        if self.verbose:\n",
    "            print('Before action:')\n",
    "            for class_id in range(self.num_classes):\n",
    "                print(f\"Class {class_id + 1}: {self.target_hours[class_id]}\")\n",
    " \n",
    "        #The slot was already booked, lets reomove it (and all of its dependencies)\n",
    "        result = \"N/A\"\n",
    "        reward = 0\n",
    "        if current_subject_id != -1:\n",
    "            self.schedule[class_id, day, hour] = -1\n",
    "            self.target_hours[class_id, current_subject_id] += 1\n",
    "            result = \"Removed\"\n",
    "            reward = -0.12 #Penalty for removing a subject\n",
    "\n",
    "        \n",
    "        #See if it is an add action\n",
    "        elif subject_id < self.num_subjects:\n",
    "            #Yes its an add action, lets see if we have enough hours to actually add it\n",
    "            if self.target_hours[class_id, subject_id] > 0:\n",
    "                self.schedule[class_id, day, hour] = subject_id\n",
    "                self.target_hours[class_id, subject_id] -= 1\n",
    "                result = \"Added\"\n",
    "                reward = 0.1 #Reward for adding a subject\n",
    "            else:\n",
    "                #We are trying to add a subject that is already empty\n",
    "                reward = -0.15 #Penalty for invalid action    \n",
    "        else:\n",
    "            #We are trying to remove a subject that is not in the schedule, this is an invalid action\n",
    "            reward = -0.15 #Penalty for invalid action\n",
    "        \n",
    "            # Reward for completing a subject's required hours\n",
    "        if self.target_hours[class_id, subject_id] == 0:\n",
    "            reward += 0.2\n",
    "\n",
    "        completion_percentage = 1.0 - (self.target_hours.sum() / self.initial_hours_to_assign)\n",
    "        reward += completion_percentage * 0.1 \n",
    "\n",
    "        self.num_actions_left -= 1\n",
    "        done = self.is_done()  \n",
    "        if done:\n",
    "            reward += 1.0\n",
    "            reward += self.fitness()  #If we are done we get the full score of the schedule\n",
    "        \n",
    "  \n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Action: {action}, Class: {class_id}, Subject: {subject_id}, Day: {day}, Hour: {hour}, , current_subject_id: {current_subject_id}, Result: {result}, reward: {reward}, done: {done}\")     \n",
    "            print('After action:')\n",
    "            for class_id in range(self.num_classes):\n",
    "                print(f\"Class {class_id + 1}: {self.target_hours[class_id]}\")\n",
    "\n",
    "            if done:\n",
    "                print('Final schedule:')\n",
    "                self.render()\n",
    "                \n",
    "        truncated, info = False, {} #To be implemented later if needed\n",
    "        #Return the next state, reward, done, truncated and info\n",
    "        #return (self.target_hours, self.schedule), reward, done, truncated, info\n",
    "        return self.state2vector(), reward, done, truncated, info       \n",
    "\n",
    "\n",
    "    def is_done(self):\n",
    "        #Check if the schedule is complete\n",
    "        return np.all(self.target_hours == 0) or self.num_actions_left <= 0\n",
    "    \n",
    "    def get_action_sizes(self):\n",
    "        #Return the sizes of the action space\n",
    "        return [self.num_classes, self.num_days, self.num_hours, self.num_subjects]\n",
    "        #return np.prod(self.max_values)\n",
    "    \n",
    "    def get_state_sizes(self):\n",
    "        #Return the shapes of the state space\n",
    "        #return self.target_hours.shape, self.schedule.shape\n",
    "        return self.state2vector().shape\n",
    "\n",
    "    \n",
    "    def fitness(self):\n",
    "        #Calculate the fitness of the schedule\n",
    "        #fitness = self.num_actions_left * 0.001 #We want to maximize the number of actions left\n",
    "        fitness = 0.0\n",
    "        # target hours remaining\n",
    "        target_hours_remaining = self.target_hours.sum().sum()\n",
    "\n",
    "        fitness -= target_hours_remaining * 1\n",
    "\n",
    "        # Count the number of holes in the schedule, that is where no subject is assigned, but is surrounded by subjects\n",
    "        # If there are no subjects assigned to the edges, that is not considered a hole\n",
    "        num_holes = 0\n",
    "\n",
    "        # Create shifted versions of the schedule to compare adjacent hours\n",
    "        left_shifted = np.roll(self.schedule, shift=-1, axis=2)\n",
    "        right_shifted = np.roll(self.schedule, shift=1, axis=2)\n",
    "\n",
    "        # Identify holes: -1 in the current schedule, and not -1 in both the left and right shifted schedules\n",
    "        # Avoid considering the edges by setting the comparison for the first and last hour to False\n",
    "        holes = (self.schedule == -1) & (left_shifted != -1) & (right_shifted != -1)\n",
    "        holes[:, :, 0] = False  # Ignore first hour edge cases\n",
    "        holes[:, :, -1] = False  # Ignore last hour edge cases\n",
    "\n",
    "        # Count the number of holes\n",
    "        num_holes = np.sum(holes)\n",
    "\n",
    "        fitness -= num_holes * 0.15\n",
    "\n",
    "        #return -fitness #Swapped fitness now....\n",
    "\n",
    "        fitness *= 4.2 #\n",
    "        return fitness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an agent that can do scheduling\n",
    "The agent is of type Actor Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class ScheduleAgent(nn.Module):\n",
    "#     def __init__(self, state_size, action_sizes, hidden_dim=256, gamma=0.99):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.action_sizes = action_sizes\n",
    "#         self.gamma = gamma\n",
    "        \n",
    "#         self.shared = nn.Sequential(\n",
    "#             nn.Linear(state_size, hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim, hidden_dim),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "        \n",
    "#         self.actor_heads = nn.ModuleList([nn.Linear(hidden_dim, dim) for dim in action_sizes])\n",
    "        \n",
    "#         self.critic = nn.Sequential(\n",
    "#             nn.Linear(hidden_dim, hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim, 1)\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, state):\n",
    "#         #Go through the shared layers\n",
    "#         shared_output = self.shared(state)\n",
    "        \n",
    "#         #Each head predicts its own action, like Class, Day, Hour, Subject etc\n",
    "#         action_probs = [torch.softmax(head(shared_output), dim=-1) for head in self.actor_heads]\n",
    "\n",
    "#         #The critic predicts the value of the state\n",
    "#         state_value = self.critic(shared_output)\n",
    "        \n",
    "#         return action_probs, state_value\n",
    "    \n",
    "#     def choose_action(self, state):\n",
    "#         #device = next(self.parameters()).device\n",
    "#         #state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "       \n",
    "#         #Get the probabilities of the actions for each head\n",
    "#         with torch.no_grad():\n",
    "#             action_probs, _ = self.forward(state)\n",
    "        \n",
    "#         #Choose an action for each head\n",
    "#         #actions = [torch.multinomial(probs, 1).item() for probs in action_probs]\n",
    "#         #actions = torch.stack([torch.multinomial(probs, 1) for probs in action_probs]).squeeze(-1)\n",
    "#         actions = torch.tensor([torch.multinomial(probs[0], 1).item() for probs in action_probs], device=state.device)\n",
    "\n",
    "#         return actions\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ScheduleAgent(nn.Module):\n",
    "    def __init__(self, state_size, action_sizes, hidden_dim=256, gamma=0.99):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.action_sizes = action_sizes\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(state_size, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.actor_heads = nn.ModuleList([nn.Linear(hidden_dim, dim) for dim in action_sizes])\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, state):\n",
    "        shared_output = self.shared(state)\n",
    "        \n",
    "        action_probs = [F.softmax(head(shared_output), dim=-1) for head in self.actor_heads]\n",
    "        state_value = self.critic(shared_output)\n",
    "        \n",
    "        return action_probs, state_value\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        with torch.no_grad():\n",
    "            action_probs, _ = self.forward(state)\n",
    "        \n",
    "        actions = torch.tensor([torch.multinomial(probs[0], 1).item() for probs in action_probs], device=state.device)\n",
    "        return actions\n",
    "    \n",
    "    def get_value(self, state):\n",
    "        _, state_value = self.forward(state)\n",
    "        return state_value\n",
    "\n",
    "    def evaluate_actions(self, states, actions):\n",
    "        action_probs, state_values = self.forward(states)\n",
    "        action_log_probs = sum([torch.log(probs[torch.arange(probs.size(0)), action]) \n",
    "                                for probs, action in zip(action_probs, actions.T)])\n",
    "        return action_log_probs, state_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ScheduleGym(num_days=2, num_hours=4, num_classes=1, num_subjects=2)\n",
    "state_dim = env.get_state_sizes()[0]\n",
    "action_dims = env.get_action_sizes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ScheduleAgent(state_dim, action_dims, hidden_dim=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,_ = env.reset()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ost = agent(torch.FloatTensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ost2 = agent.choose_action(torch.FloatTensor(x).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ost2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ost2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScheduleAgent(\n",
       "  (shared): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (actor_heads): ModuleList(\n",
       "    (0): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (2): Linear(in_features=2048, out_features=4, bias=True)\n",
       "    (3): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  )\n",
       "  (critic): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Send the agent to the correct device\n",
    "agent.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(agent.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# num_episodes = 10\n",
    "# gamma = 0.99\n",
    "\n",
    "# end_rewards = []\n",
    "# total_rewards = []\n",
    "# num_actions_per_episode = []\n",
    "\n",
    "# for episode in range(num_episodes):\n",
    "#     state, _ = env.reset()\n",
    "#     state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "#     done = False\n",
    "#     episode_reward = 0.0\n",
    "#     episode_counter = 0\n",
    "    \n",
    "#     while not done:\n",
    "#         actions = agent.choose_action(state)\n",
    "#         actions_np = actions.cpu().numpy()\n",
    "#         next_state, reward, done , _, _ = env.step(actions_np)\n",
    "        \n",
    "#         #state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "#         next_state = torch.FloatTensor(next_state).unsqueeze(0).to(device)\n",
    "#         reward = torch.FloatTensor([reward]).unsqueeze(0).to(device)\n",
    "#         done = torch.FloatTensor([int(done)]).unsqueeze(0).to(device)\n",
    "        \n",
    "#         action_probs, state_value = agent(state)\n",
    "#         _, next_state_value = agent(next_state)\n",
    "        \n",
    "#         td_error = reward + gamma * next_state_value * (1 - done) - state_value\n",
    "        \n",
    "#         actor_loss = -(1 / len(action_probs)) * sum(torch.log(probs[0, action]) for probs, action in zip(action_probs, actions)) * td_error.detach()\n",
    "#         #actor_loss = -(1 / len(action_probs)) * torch.sum(torch.log(action_probs[torch.arange(len(actions)), actions])) * td_error.detach()\n",
    "#         critic_loss = td_error.pow(2)\n",
    "        \n",
    "#         loss = actor_loss + critic_loss\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.mean().backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         state = next_state\n",
    "#         episode_reward += reward\n",
    "#         episode_counter += 1\n",
    "\n",
    "#     end_reward = env.fitness()\n",
    "#     end_rewards.append(end_reward)\n",
    "#     total_rewards.append(episode_reward)\n",
    "#     num_actions_per_episode.append(episode_counter)\n",
    "    \n",
    "#     if episode % 100 == 0:\n",
    "#         print(f\"Episode {episode}, Reward: {episode_reward}\")\n",
    "\n",
    "# print(\"Final schedule:\")\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0026, device='cuda:0')\n",
      "tensor(-0.3295, device='cuda:0')\n",
      "tensor(-224.1134, device='cuda:0')\n",
      "tensor(-1.3746, device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(4.3372e-07, device='cuda:0')\n",
      "tensor(1.4901e-08, device='cuda:0')\n",
      "tensor(8.2013e-07, device='cuda:0')\n",
      "tensor(1.8626e-08, device='cuda:0')\n",
      "tensor(-5.0258e-07, device='cuda:0')\n",
      "tensor(-7.4506e-09, device='cuda:0')\n",
      "tensor(-241.6289, device='cuda:0')\n",
      "tensor(-3.7058, device='cuda:0')\n",
      "tensor(198.0084, device='cuda:0')\n",
      "tensor(6.6234, device='cuda:0')\n",
      "Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cerion\\AppData\\Local\\Temp\\ipykernel_35432\\2682911990.py:50: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  returns = torch.FloatTensor(returns).to(device)\n",
      "C:\\Users\\cerion\\AppData\\Local\\Temp\\ipykernel_35432\\3519465919.py:49: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3618.)\n",
      "  for probs, action in zip(action_probs, actions.T)])\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_episodes = 10000\n",
    "gamma = 0.99\n",
    "end_rewards = []\n",
    "total_rewards = []\n",
    "num_actions_per_episode = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset(seed=42)\n",
    "    #env.render() #Debug\n",
    "    state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "    done = False\n",
    "    episode_reward = 0.0\n",
    "    episode_counter = 0\n",
    "    \n",
    "    states, actions, rewards, next_states, dones = [], [], [], [], []\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.choose_action(state)\n",
    "        next_state, reward, done, _, _ = env.step(action.cpu().numpy())\n",
    "        \n",
    "        next_state = torch.FloatTensor(next_state).unsqueeze(0).to(device)\n",
    "        reward = torch.FloatTensor([reward]).unsqueeze(0).to(device)\n",
    "        done = torch.FloatTensor([int(done)]).unsqueeze(0).to(device)\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        next_states.append(next_state)\n",
    "        dones.append(done)\n",
    "        \n",
    "        state = next_state\n",
    "        episode_reward += reward.item()\n",
    "        episode_counter += 1\n",
    "        #print(f't:{episode_counter} Actions: {action} reward: {reward.item()} total_reward: {episode_reward}')\n",
    "    \n",
    "    # Convert lists to tensors\n",
    "    states = torch.cat(states)\n",
    "    actions = torch.cat(actions)\n",
    "    rewards = torch.cat(rewards)\n",
    "    next_states = torch.cat(next_states)\n",
    "    dones = torch.cat(dones)\n",
    "    \n",
    "    # Compute returns and advantages\n",
    "    returns = []\n",
    "    R = 0\n",
    "    for reward, done in zip(reversed(rewards.cpu().numpy()), reversed(dones.cpu().numpy())):\n",
    "        R = reward + gamma * R * (1 - done)\n",
    "        returns.insert(0, R)\n",
    "    returns = torch.FloatTensor(returns).to(device)\n",
    "\n",
    "    state_values = agent.get_value(states).squeeze()  # Ensure it's 1D\n",
    "    next_state_values = agent.get_value(next_states).squeeze()  # Ensure it's 1D\n",
    "\n",
    "    # Ensure returns has the same shape as state_values\n",
    "    returns = returns.view_as(state_values)\n",
    "\n",
    "    td_errors = rewards.squeeze() + gamma * next_state_values * (1 - dones.squeeze()) - state_values\n",
    "    advantages = td_errors.detach()\n",
    "\n",
    "    # Compute losses\n",
    "    action_log_probs, _ = agent.evaluate_actions(states, actions)\n",
    "    actor_loss = -(action_log_probs * advantages).mean()\n",
    "    critic_loss = F.mse_loss(state_values, returns)\n",
    "\n",
    "    loss = actor_loss + 0.5 * critic_loss\n",
    "        \n",
    "    # Perform the update\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    #print the gradients\n",
    "    if True:\n",
    "        for param in agent.parameters():\n",
    "            print(param.grad.data.sum())\n",
    "\n",
    "    break\n",
    "    #Clip the gradients\n",
    "    torch.nn.utils.clip_grad_norm_(agent.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    end_reward = env.fitness()\n",
    "    end_rewards.append(end_reward)\n",
    "    total_rewards.append(episode_reward)\n",
    "    num_actions_per_episode.append(episode_counter)\n",
    "\n",
    "    #Debug\n",
    "    #print('End result:')\n",
    "    #env.render()\n",
    "    # if episode_reward > 2.051:\n",
    "    #     print('wtf')\n",
    "        \n",
    "    # if episode_counter <= 7.0:\n",
    "    #     print('found perfect solution')\n",
    "        \n",
    "    if episode % 5 == 0:\n",
    "        print(f\"Episode {episode}, Reward: {episode_reward}, End reward: {end_reward}, Loss: {loss.item()}\")\n",
    "\n",
    "print('Training complete')\n",
    "# print(\"Final schedule:\")\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.clip_grad_norm_(agent.parameters(), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0002, device='cuda:0')\n",
      "tensor(-0.0231, device='cuda:0')\n",
      "tensor(-15.7311, device='cuda:0')\n",
      "tensor(-0.0965, device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(0., device='cuda:0')\n",
      "tensor(3.0949e-08, device='cuda:0')\n",
      "tensor(1.1642e-09, device='cuda:0')\n",
      "tensor(5.8091e-08, device='cuda:0')\n",
      "tensor(1.6298e-09, device='cuda:0')\n",
      "tensor(-3.5734e-08, device='cuda:0')\n",
      "tensor(-4.6566e-10, device='cuda:0')\n",
      "tensor(-16.9606, device='cuda:0')\n",
      "tensor(-0.2601, device='cuda:0')\n",
      "tensor(13.8987, device='cuda:0')\n",
      "tensor(0.4649, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in agent.parameters():\n",
    "    print(param.grad.data.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Actions per episode')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAGwCAYAAAC5ACFFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsIklEQVR4nO3deXSUVZ7/8U+FkAUwiUBIEaiISkaC0qBgQtBpbMkQRMVoHDHDLiODAtoGEYIIao8dd9BG4bg17QgN4jaKCE0HXAlbgsgWGrtlEaggxlQAJQnJ/f3hj5ouCdcUpqhUeL/OeQ5d97m36nvvSVuf89StpxzGGCMAAADUKSzYBQAAADRmhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFiEB7uApqC2tlb79+/XOeecI4fDEexyAABAPRhjdPjwYSUmJios7NTXjwhLDWD//v1yuVzBLgMAAJyGvXv3qmPHjqc8T1hqAOecc46kHxc7JiYmyNUAAID6qKiokMvl8r6PnwphqQGc+OgtJiaGsAQAQIj5uS00bPAGAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFiEXlp577jl16tRJUVFRSktL07p166z9Fy9erC5duigqKkrdunXT0qVLT9l37NixcjgcmjVrVgNXDQAAQlVIhaVFixYpNzdXM2bMUHFxsbp3767MzEwdPHiwzv6rV69WTk6ORo8erY0bNyorK0tZWVnasmXLSX3ffvttrVmzRomJiYGeBgAACCEhFZaefvpp3X777Ro1apS6du2quXPnqkWLFnrllVfq7P/MM89owIABmjRpklJSUvS73/1Ol112mWbPnu3Tb9++fZowYYLmz5+v5s2bn4mpAACAEBEyYamqqkpFRUXKyMjwtoWFhSkjI0OFhYV1jiksLPTpL0mZmZk+/WtrazVs2DBNmjRJF198cb1qqaysVEVFhc8BAACappAJS4cOHVJNTY0SEhJ82hMSEuR2u+sc43a7f7b/Y489pvDwcN111131riU/P1+xsbHew+Vy+TETAAAQSkImLAVCUVGRnnnmGc2bN08Oh6Pe4/Ly8uTxeLzH3r17A1glAAAIppAJS23btlWzZs1UWlrq015aWiqn01nnGKfTae3/ySef6ODBg0pKSlJ4eLjCw8O1e/duTZw4UZ06dTplLZGRkYqJifE5AABA0xQyYSkiIkI9e/ZUQUGBt622tlYFBQVKT0+vc0x6erpPf0lasWKFt/+wYcP0xRdf6PPPP/ceiYmJmjRpkpYvXx64yQAAgJARHuwC/JGbm6sRI0aoV69eSk1N1axZs3T06FGNGjVKkjR8+HB16NBB+fn5kqS7775bffv21VNPPaVrr71WCxcu1IYNG/TCCy9Iktq0aaM2bdr4vEbz5s3ldDp10UUXndnJAQCARimkwtLgwYP1zTffaPr06XK73erRo4eWLVvm3cS9Z88ehYX938WyPn36aMGCBZo2bZqmTp2q5ORkvfPOO7rkkkuCNQUAABBiHMYYE+wiQl1FRYViY2Pl8XjYvwQAQIio7/t3yOxZAgAACAbCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFiEXlp577jl16tRJUVFRSktL07p166z9Fy9erC5duigqKkrdunXT0qVLveeqq6s1efJkdevWTS1btlRiYqKGDx+u/fv3B3oaAAAgRIRUWFq0aJFyc3M1Y8YMFRcXq3v37srMzNTBgwfr7L969Wrl5ORo9OjR2rhxo7KyspSVlaUtW7ZIkr7//nsVFxfrgQceUHFxsd566y3t2LFDgwYNOpPTAgAAjZjDGGOCXUR9paWl6fLLL9fs2bMlSbW1tXK5XJowYYKmTJlyUv/Bgwfr6NGjWrJkibetd+/e6tGjh+bOnVvna6xfv16pqanavXu3kpKS6lVXRUWFYmNj5fF4FBMTcxozAwAAZ1p9379D5spSVVWVioqKlJGR4W0LCwtTRkaGCgsL6xxTWFjo01+SMjMzT9lfkjwejxwOh+Li4k7Zp7KyUhUVFT4HAABomkImLB06dEg1NTVKSEjwaU9ISJDb7a5zjNvt9qv/sWPHNHnyZOXk5FgTZn5+vmJjY72Hy+XyczYAACBUhExYCrTq6mrdcsstMsZozpw51r55eXnyeDzeY+/evWeoSgAAcKaFB7uA+mrbtq2aNWum0tJSn/bS0lI5nc46xzidznr1PxGUdu/erZUrV/7svqPIyEhFRkaexiwAAECoCZkrSxEREerZs6cKCgq8bbW1tSooKFB6enqdY9LT0336S9KKFSt8+p8ISjt37tRf//pXtWnTJjATAAAAISlkrixJUm5urkaMGKFevXopNTVVs2bN0tGjRzVq1ChJ0vDhw9WhQwfl5+dLku6++2717dtXTz31lK699lotXLhQGzZs0AsvvCDpx6B08803q7i4WEuWLFFNTY13P1Pr1q0VERERnIkCAIBGI6TC0uDBg/XNN99o+vTpcrvd6tGjh5YtW+bdxL1nzx6Fhf3fxbI+ffpowYIFmjZtmqZOnark5GS98847uuSSSyRJ+/bt07vvvitJ6tGjh89rrVq1SlddddUZmRcAAGi8Quo+S40V91kCACD0NLn7LAEAAAQDYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYhNen07vvvlvvJxw0aNBpFwMAANDY1CssZWVl+Tx2OBwyxvg8PqGmpqZhKgMAAGgE6vUxXG1trff4y1/+oh49euiDDz5QeXm5ysvLtXTpUl122WVatmxZoOsFAAA4o+p1Zemf/fa3v9XcuXN15ZVXetsyMzPVokULjRkzRtu3b2/QAgEAAILJ7w3ef//73xUXF3dSe2xsrHbt2tUAJQEAADQefoelyy+/XLm5uSotLfW2lZaWatKkSUpNTW3Q4gAAAILN77D08ssv68CBA0pKSlLnzp3VuXNnJSUlad++fXr55ZcDUSMAAEDQ+L1nKTk5WV988YVWrFihkpISSVJKSooyMjJ8vhUHAADQFPgVlqqrqxUdHa3PP/9c/fv3V//+/QNVFwAAQKPg18dwzZs3V1JSEvdSAgAAZw2/9yzdf//9mjp1qsrKygJRDwAAQKPi956l2bNn68svv1RiYqLOO+88tWzZ0ud8cXFxgxUHAAAQbH6HpZ/+9AkAAEBT5jD//CNvOC0VFRWKjY2Vx+NRTExMsMsBAAD1UN/3b7/3LAEAAJxN/P4YrqamRjNnztTrr7+uPXv2qKqqyuc8G78BAEBT4veVpYceekhPP/20Bg8eLI/Ho9zcXN10000KCwvTgw8+GIASAQAAgsfvsDR//ny9+OKLmjhxosLDw5WTk6OXXnpJ06dP15o1awJRIwAAQND4HZbcbre6desmSWrVqpU8Ho8k6brrrtP777/fsNUBAAAEmd9hqWPHjjpw4IAk6cILL9Rf/vIXSdL69esVGRnZsNUBAAAEmd9h6cYbb1RBQYEkacKECXrggQeUnJys4cOH67bbbmvwAgEAAILpF99nac2aNVq9erWSk5N1/fXXN1RdIYX7LAEAEHrq+/7t960Dfqp3797q3bv3L30aAACARsnvsJSUlKSrrrpKffv21VVXXaULL7wwEHUBAAA0Cn7vWfr973+vqKgoPfbYY0pOTpbL5dLQoUP14osvaufOnYGoEQAAIGh+0Z6lAwcO6KOPPtKSJUu0aNEi1dbWqqampiHrCwnsWQIAIPQEdM/S999/r08//VQffvihVq1apY0bN+qSSy7RVVdddbr1AgAANEp+h6U+ffpo48aNSklJ0VVXXaUpU6bo17/+tc4999xA1AcAABBUfu9ZKikpUcuWLdWlSxd16dJFKSkpBCUAANBk+R2Wvv32W61cuVK9e/fW8uXLdcUVV6hDhw76j//4D7344ouBqBEAACBoftEGb2OMioqKNHv2bM2fP58N3mzwBgAgZARsg3dxcbE+/PBDffjhh/r00091+PBhdevWTRMmTFDfvn1/UdEAAACNjd9hKTU1VZdeeqn69u2r22+/Xb/+9a8VGxsbiNoAAACCzu+wVFZWxkdNAADgrOH3Bu+YmBiVl5frpZdeUl5ensrKyiT9+PHcvn37GrxAAACAYPI7LH3xxRdKTk7WY489pieffFLl5eWSpLfeekt5eXkNXd9JnnvuOXXq1ElRUVFKS0vTunXrrP0XL16sLl26KCoqSt26ddPSpUt9zhtjNH36dLVv317R0dHKyMjgZ1sAAICX32EpNzdXo0aN0s6dOxUVFeVtHzhwoD7++OMGLe6nFi1apNzcXM2YMUPFxcXq3r27MjMzdfDgwTr7r169Wjk5ORo9erQ2btyorKwsZWVlacuWLd4+jz/+uJ599lnNnTtXa9euVcuWLZWZmaljx44FdC4AACA0+H3rgNjYWBUXF+vCCy/UOeeco02bNumCCy7Q7t27ddFFFwU0ZKSlpenyyy/X7NmzJUm1tbVyuVyaMGGCpkyZclL/wYMH6+jRo1qyZIm3rXfv3urRo4fmzp0rY4wSExM1ceJE3XvvvZIkj8ejhIQEzZs3T7feemu96uLWAQAAhJ76vn/7fWUpMjJSFRUVJ7X/7W9/U3x8vL9PV29VVVUqKipSRkaGty0sLEwZGRkqLCysc0xhYaFPf0nKzMz09v/qq6/kdrt9+sTGxiotLe2UzylJlZWVqqio8DkAAEDT5HdYGjRokB5++GFVV1dLkhwOh/bs2aPJkycrOzu7wQs84dChQ6qpqVFCQoJPe0JCgtxud51j3G63tf+Jf/15TknKz89XbGys93C5XH7PBwAAhAa/w9JTTz2lI0eOqF27dvrhhx/Ut29fde7cWa1atdIjjzwSiBobnby8PHk8Hu+xd+/eYJcEAAACxO/7LMXGxmrFihX69NNP9cUXX+jIkSO67LLLTvq4q6G1bdtWzZo1U2lpqU97aWmpnE5nnWOcTqe1/4l/S0tL1b59e58+PXr0OGUtkZGRioyMPJ1pAACAEOP3laUTrrzySt1555267777lJGRoeLiYl133XUNWZuPiIgI9ezZUwUFBd622tpaFRQUKD09vc4x6enpPv0lacWKFd7+559/vpxOp0+fiooKrV279pTPCQAAzi5+haXly5fr3nvv1dSpU/WPf/xDklRSUqKsrCxdfvnlqq2tDUiRJ+Tm5urFF1/Un/70J23fvl133HGHjh49qlGjRkmShg8f7nOvp7vvvlvLli3TU089pZKSEj344IPasGGDxo8fL+nH/Va//e1v9d///d969913tXnzZg0fPlyJiYnKysoK6FwAAEBoqPfHcC+//LJuv/12tW7dWt99951eeuklPf3005owYYIGDx6sLVu2KCUlJZC1avDgwfrmm280ffp0ud1u9ejRQ8uWLfNu0N6zZ4/Cwv4v//Xp00cLFizQtGnTNHXqVCUnJ+udd97RJZdc4u1z33336ejRoxozZozKy8t15ZVXatmyZT73kAIAAGevet9n6Ve/+pWGDRumSZMm6c0339S///u/q3fv3nr99dfVsWPHQNfZqHGfJQAAQk9937/rHZZatmyprVu3qlOnTjLGKDIyUqtWrdIVV1zRYEWHKsISAAChp8FvSvnDDz+oRYsWkn7c6xMZGenzDTIAAICmyK9bB7z00ktq1aqVJOn48eOaN2+e2rZt69PnrrvuarjqAAAAgqzeH8N16tRJDofD/mQOh/dbcmcTPoYDACD01Pf9u95Xlnbt2tUQdQEAAISU074pJQAAwNmAsAQAAGBBWAIAALAgLAEAAFgQlgAAACzq9W24ioqKej8hX50HAABNSb3CUlxc3M/eY+mEmpqaX1QQAABAY1KvsLRq1Srv/961a5emTJmikSNHKj09XZJUWFioP/3pT8rPzw9MlQAAAEFS7zt4n9CvXz/953/+p3JycnzaFyxYoBdeeEEffvhhQ9YXEriDNwAAoafBf0j3hMLCQvXq1euk9l69emndunX+Ph0AAECj5ndYcrlcevHFF09qf+mll+RyuRqkKAAAgMai3r8Nd8LMmTOVnZ2tDz74QGlpaZKkdevWaefOnXrzzTcbvEAAAIBg8vvK0sCBA7Vz505df/31KisrU1lZma6//nr97W9/08CBAwNRIwAAQND4vcEbJ2ODNwAAoae+799+fwwnSeXl5Vq3bp0OHjyo2tpan3PDhw8/nacEAABolPwOS++9956GDBmiI0eOKCYmxudmlQ6Hg7AEAACaFL/3LE2cOFG33Xabjhw5ovLycn333Xfeo6ysLBA1AgAABI3fYWnfvn2666671KJFi0DUAwAA0Kj4HZYyMzO1YcOGQNQCAADQ6Pi9Z+naa6/VpEmTtG3bNnXr1k3Nmzf3OT9o0KAGKw4AACDY/L51QFjYqS9GORwO1dTU/OKiQg23DgAAIPQE7NYBP71VAAAAQFPm954lAACAs0m9w9LAgQPl8Xi8jx999FGVl5d7H3/77bfq2rVrgxYHAAAQbPUOS8uXL1dlZaX38e9//3uf+yodP35cO3bsaNjqAAAAgqzeYemn+8D5STkAAHA2YM8SAACARb3DksPh8PkduBNtAAAATVm9bx1gjNHIkSMVGRkpSTp27JjGjh2rli1bSpLPfiYAAICmot5hacSIET6Phw4delKf4cOH//KKAAAAGpF6h6U//vGPgawDAACgUWKDNwAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFiETFgqKyvTkCFDFBMTo7i4OI0ePVpHjhyxjjl27JjGjRunNm3aqFWrVsrOzlZpaan3/KZNm5STkyOXy6Xo6GilpKTomWeeCfRUAABACAmZsDRkyBBt3bpVK1as0JIlS/Txxx9rzJgx1jH33HOP3nvvPS1evFgfffSR9u/fr5tuusl7vqioSO3atdNrr72mrVu36v7771deXp5mz54d6OkAAIAQ4TDGmGAX8XO2b9+url27av369erVq5ckadmyZRo4cKC+/vprJSYmnjTG4/EoPj5eCxYs0M033yxJKikpUUpKigoLC9W7d+86X2vcuHHavn27Vq5cecp6KisrVVlZ6X1cUVEhl8slj8ejmJiYXzJVAABwhlRUVCg2NvZn379D4spSYWGh4uLivEFJkjIyMhQWFqa1a9fWOaaoqEjV1dXKyMjwtnXp0kVJSUkqLCw85Wt5PB61bt3aWk9+fr5iY2O9h8vl8nNGAAAgVIREWHK73WrXrp1PW3h4uFq3bi23233KMREREYqLi/NpT0hIOOWY1atXa9GiRT/78V5eXp48Ho/32Lt3b/0nAwAAQkpQw9KUKVPkcDisR0lJyRmpZcuWLbrhhhs0Y8YM9e/f39o3MjJSMTExPgcAAGiawoP54hMnTtTIkSOtfS644AI5nU4dPHjQp/348eMqKyuT0+msc5zT6VRVVZXKy8t9ri6VlpaeNGbbtm3q16+fxowZo2nTpp3WXAAAQNMU1LAUHx+v+Pj4n+2Xnp6u8vJyFRUVqWfPnpKklStXqra2VmlpaXWO6dmzp5o3b66CggJlZ2dLknbs2KE9e/YoPT3d22/r1q26+uqrNWLECD3yyCMNMCsAANCUhMS34STpmmuuUWlpqebOnavq6mqNGjVKvXr10oIFCyRJ+/btU79+/fTqq68qNTVVknTHHXdo6dKlmjdvnmJiYjRhwgRJP+5Nkn786O3qq69WZmamnnjiCe9rNWvWrF4h7oT67qYHAACNR33fv4N6Zckf8+fP1/jx49WvXz+FhYUpOztbzz77rPd8dXW1duzYoe+//97bNnPmTG/fyspKZWZm6vnnn/eef+ONN/TNN9/otdde02uvveZtP++887Rr164zMi8AANC4hcyVpcaMK0sAAISeJnWfJQAAgGAhLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYBEyYamsrExDhgxRTEyM4uLiNHr0aB05csQ65tixYxo3bpzatGmjVq1aKTs7W6WlpXX2/fbbb9WxY0c5HA6Vl5cHYAYAACAUhUxYGjJkiLZu3aoVK1ZoyZIl+vjjjzVmzBjrmHvuuUfvvfeeFi9erI8++kj79+/XTTfdVGff0aNH61e/+lUgSgcAACHMYYwxwS7i52zfvl1du3bV+vXr1atXL0nSsmXLNHDgQH399ddKTEw8aYzH41F8fLwWLFigm2++WZJUUlKilJQUFRYWqnfv3t6+c+bM0aJFizR9+nT169dP3333neLi4k5ZT2VlpSorK72PKyoq5HK55PF4FBMT00CzBgAAgVRRUaHY2Nifff8OiStLhYWFiouL8wYlScrIyFBYWJjWrl1b55iioiJVV1crIyPD29alSxclJSWpsLDQ27Zt2zY9/PDDevXVVxUWVr/lyM/PV2xsrPdwuVynOTMAANDYhURYcrvdateunU9beHi4WrduLbfbfcoxERERJ10hSkhI8I6prKxUTk6OnnjiCSUlJdW7nry8PHk8Hu+xd+9e/yYEAABCRlDD0pQpU+RwOKxHSUlJwF4/Ly9PKSkpGjp0qF/jIiMjFRMT43MAAICmKTyYLz5x4kSNHDnS2ueCCy6Q0+nUwYMHfdqPHz+usrIyOZ3OOsc5nU5VVVWpvLzc5+pSaWmpd8zKlSu1efNmvfHGG5KkE9u32rZtq/vvv18PPfTQac4MAAA0FUENS/Hx8YqPj//Zfunp6SovL1dRUZF69uwp6cegU1tbq7S0tDrH9OzZU82bN1dBQYGys7MlSTt27NCePXuUnp4uSXrzzTf1ww8/eMesX79et912mz755BNdeOGFv3R6AACgCQhqWKqvlJQUDRgwQLfffrvmzp2r6upqjR8/Xrfeeqv3m3D79u1Tv3799Oqrryo1NVWxsbEaPXq0cnNz1bp1a8XExGjChAlKT0/3fhPup4Ho0KFD3tezfRsOAACcPUIiLEnS/PnzNX78ePXr109hYWHKzs7Ws88+6z1fXV2tHTt26Pvvv/e2zZw509u3srJSmZmZev7554NRPgAACFEhcZ+lxq6+92kAAACNR5O6zxIAAECwEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALMKDXUBTYIyRJFVUVAS5EgAAUF8n3rdPvI+fCmGpARw+fFiS5HK5glwJAADw1+HDhxUbG3vK8w7zc3EKP6u2tlb79+/XOeecI4fDEexygqqiokIul0t79+5VTExMsMtpsljnM4e1PjNY5zODdfZljNHhw4eVmJiosLBT70ziylIDCAsLU8eOHYNdRqMSExPD/xHPANb5zGGtzwzW+cxgnf+P7YrSCWzwBgAAsCAsAQAAWBCW0KAiIyM1Y8YMRUZGBruUJo11PnNY6zODdT4zWOfTwwZvAAAAC64sAQAAWBCWAAAALAhLAAAAFoQlAAAAC8IS/FZWVqYhQ4YoJiZGcXFxGj16tI4cOWIdc+zYMY0bN05t2rRRq1atlJ2drdLS0jr7fvvtt+rYsaMcDofKy8sDMIPQEIh13rRpk3JycuRyuRQdHa2UlBQ988wzgZ5Ko/Lcc8+pU6dOioqKUlpamtatW2ftv3jxYnXp0kVRUVHq1q2bli5d6nPeGKPp06erffv2io6OVkZGhnbu3BnIKYSEhlzn6upqTZ48Wd26dVPLli2VmJio4cOHa//+/YGeRqPX0H/P/2zs2LFyOByaNWtWA1cdggzgpwEDBpju3bubNWvWmE8++cR07tzZ5OTkWMeMHTvWuFwuU1BQYDZs2GB69+5t+vTpU2ffG264wVxzzTVGkvnuu+8CMIPQEIh1fvnll81dd91lPvzwQ/P3v//d/M///I+Jjo42f/jDHwI9nUZh4cKFJiIiwrzyyitm69at5vbbbzdxcXGmtLS0zv6fffaZadasmXn88cfNtm3bzLRp00zz5s3N5s2bvX0effRRExsba9555x2zadMmM2jQIHP++eebH3744UxNq9Fp6HUuLy83GRkZZtGiRaakpMQUFhaa1NRU07NnzzM5rUYnEH/PJ7z11lume/fuJjEx0cycOTPAM2n8CEvwy7Zt24wks379em/bBx98YBwOh9m3b1+dY8rLy03z5s3N4sWLvW3bt283kkxhYaFP3+eff9707dvXFBQUnNVhKdDr/M/uvPNO85vf/Kbhim/EUlNTzbhx47yPa2pqTGJiosnPz6+z/y233GKuvfZan7a0tDTzX//1X8YYY2pra43T6TRPPPGE93x5ebmJjIw0f/7znwMwg9DQ0Otcl3Xr1hlJZvfu3Q1TdAgK1Dp//fXXpkOHDmbLli3mvPPOIywZY/gYDn4pLCxUXFycevXq5W3LyMhQWFiY1q5dW+eYoqIiVVdXKyMjw9vWpUsXJSUlqbCw0Nu2bds2Pfzww3r11VetP2h4NgjkOv+Ux+NR69atG674RqqqqkpFRUU+6xMWFqaMjIxTrk9hYaFPf0nKzMz09v/qq6/kdrt9+sTGxiotLc265k1ZINa5Lh6PRw6HQ3FxcQ1Sd6gJ1DrX1tZq2LBhmjRpki6++OLAFB+Czu53JPjN7XarXbt2Pm3h4eFq3bq13G73KcdERESc9B+1hIQE75jKykrl5OToiSeeUFJSUkBqDyWBWuefWr16tRYtWqQxY8Y0SN2N2aFDh1RTU6OEhASfdtv6uN1ua/8T//rznE1dINb5p44dO6bJkycrJyfnrP0x2ECt82OPPabw8HDdddddDV90CCMsQZI0ZcoUORwO61FSUhKw18/Ly1NKSoqGDh0asNdoDIK9zv9sy5YtuuGGGzRjxgz179//jLwm8EtVV1frlltukTFGc+bMCXY5TUpRUZGeeeYZzZs3Tw6HI9jlNCrhwS4AjcPEiRM1cuRIa58LLrhATqdTBw8e9Gk/fvy4ysrK5HQ66xzndDpVVVWl8vJyn6sepaWl3jErV67U5s2b9cYbb0j68RtGktS2bVvdf//9euihh05zZo1LsNf5hG3btqlfv34aM2aMpk2bdlpzCTVt27ZVs2bNTvoWZl3rc4LT6bT2P/FvaWmp2rdv79OnR48eDVh96AjEOp9wIijt3r1bK1euPGuvKkmBWedPPvlEBw8e9Lm6X1NTo4kTJ2rWrFnatWtXw04ilAR70xRCy4mNxxs2bPC2LV++vF4bj9944w1vW0lJic/G4y+//NJs3rzZe7zyyitGklm9evUpv9nRlAVqnY0xZsuWLaZdu3Zm0qRJgZtAI5WammrGjx/vfVxTU2M6dOhg3RB73XXX+bSlp6eftMH7ySef9J73eDxs8G7gdTbGmKqqKpOVlWUuvvhic/DgwcAUHmIaep0PHTrk89/hzZs3m8TERDN58mRTUlISuImEAMIS/DZgwABz6aWXmrVr15pPP/3UJCcn+3yl/euvvzYXXXSRWbt2rbdt7NixJikpyaxcudJs2LDBpKenm/T09FO+xqpVq87qb8MZE5h13rx5s4mPjzdDhw41Bw4c8B5ny5vPwoULTWRkpJk3b57Ztm2bGTNmjImLizNut9sYY8ywYcPMlClTvP0/++wzEx4ebp588kmzfft2M2PGjDpvHRAXF2f+93//13zxxRfmhhtu4NYBDbzOVVVVZtCgQaZjx47m888/9/nbraysDMocG4NA/D3/FN+G+xFhCX779ttvTU5OjmnVqpWJiYkxo0aNMocPH/ae/+qrr4wks2rVKm/bDz/8YO68805z7rnnmhYtWpgbb7zRHDhw4JSvQVgKzDrPmDHDSDrpOO+8887gzILrD3/4g0lKSjIREREmNTXVrFmzxnuub9++ZsSIET79X3/9dfMv//IvJiIiwlx88cXm/fff9zlfW1trHnjgAZOQkGAiIyNNv379zI4dO87EVBq1hlznE3/rdR3//Pd/Nmrov+efIiz9yGHM/98cAgAAgJPwbTgAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQBnrV27dsnhcOjzzz8P2GuMHDlSWVlZAXt+AIFHWAIQskaOHCmHw3HSMWDAgHqNd7lcOnDggC655JIAVwoglIUHuwAA+CUGDBigP/7xjz5tkZGR9RrbrFkzOZ3OQJQFoAnhyhKAkBYZGSmn0+lznHvuuZIkh8OhOXPm6JprrlF0dLQuuOACvfHGG96xP/0Y7rvvvtOQIUMUHx+v6OhoJScn+wSxzZs36+qrr1Z0dLTatGmjMWPG6MiRI97zNTU1ys3NVVxcnNq0aaP77rtPP/35zdraWuXn5+v8889XdHS0unfv7lMTgMaHsASgSXvggQeUnZ2tTZs2aciQIbr11lu1ffv2U/bdtm2bPvjgA23fvl1z5sxR27ZtJUlHjx5VZmamzj33XK1fv16LFy/WX//6V40fP947/qmnntK8efP0yiuv6NNPP1VZWZnefvttn9fIz8/Xq6++qrlz52rr1q265557NHToUH300UeBWwQAv4wBgBA1YsQI06xZM9OyZUuf45FHHjHGGCPJjB071mdMWlqaueOOO4wxxnz11VdGktm4caMxxpjrr7/ejBo1qs7XeuGFF8y5555rjhw54m17//33TVhYmHG73cYYY9q3b28ef/xx7/nq6mrTsWNHc8MNNxhjjDl27Jhp0aKFWb16tc9zjx492uTk5Jz+QgAIKPYsAQhpv/nNbzRnzhyfttatW3v/d3p6us+59PT0U3777Y477lB2draKi4vVv39/ZWVlqU+fPpKk7du3q3v37mrZsqW3/xVXXKHa2lrt2LFDUVFROnDggNLS0rznw8PD1atXL+9HcV9++aW+//57/du//ZvP61ZVVenSSy/1f/IAzgjCEoCQ1rJlS3Xu3LlBnuuaa67R7t27tXTpUq1YsUL9+vXTuHHj9OSTTzbI85/Y3/T++++rQ4cOPufquykdwJnHniUATdqaNWtOepySknLK/vHx8RoxYoRee+01zZo1Sy+88IIkKSUlRZs2bdLRo0e9fT/77DOFhYXpoosuUmxsrNq3b6+1a9d6zx8/flxFRUXex127dlVkZKT27Nmjzp07+xwul6uhpgyggXFlCUBIq6yslNvt9mkLDw/3bsxevHixevXqpSuvvFLz58/XunXr9PLLL9f5XNOnT1fPnj118cUXq7KyUkuWLPEGqyFDhmjGjBkaMWKEHnzwQX3zzTeaMGGChg0bpoSEBEnS3XffrUcffVTJycnq0qWLnn76aZWXl3uf/5xzztG9996re+65R7W1tbryyivl8Xj02WefKSYmRiNGjAjACgH4pQhLAELasmXL1L59e5+2iy66SCUlJZKkhx56SAsXLtSdd96p9u3b689//rO6du1a53NFREQoLy9Pu3btUnR0tP71X/9VCxculCS1aNFCy5cv1913363LL79cLVq0UHZ2tp5++mnv+IkTJ+rAgQMaMWKEwsLCdNttt+nGG2+Ux+Px9vnd736n+Ph45efn6x//+Ifi4uJ02WWXaerUqQ29NAAaiMOYn9wEBACaCIfDobfffpufGwHwi7BnCQAAwIKwBAAAYMGeJQBNFrsMADQEriwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALD4f+0NBGCFw+2lAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the rewards\n",
    "total_rewards_rolling = [np.mean(total_rewards[max(0, i-100):i+1]) for i in range(len(total_rewards))]\n",
    "plt.plot(total_rewards_rolling)\n",
    "#Plot the 100 episode rolling average\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "\n",
    "# plot the end rewards\n",
    "end_rewards_rolling = [np.mean(end_rewards[max(0, i-100):i+1]) for i in range(len(end_rewards))]\n",
    "plt.figure()\n",
    "plt.plot(end_rewards_rolling)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('End Reward')\n",
    "\n",
    "# plot the end rewards\n",
    "num_actions_per_episode_rolling = [np.mean(num_actions_per_episode[max(0, i-100):i+1]) for i in range(len(num_actions_per_episode))]\n",
    "plt.figure()\n",
    "plt.plot(num_actions_per_episode_rolling)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Actions per episode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_actor_critic_agent(agent, env, n_episodes=5, seed=None):\n",
    "    for i_episode in range(1, n_episodes + 1):\n",
    "        state, info = env.reset(seed=seed)\n",
    "        done = False\n",
    "        score = 0\n",
    "        max_t = 5000\n",
    "        t = 0\n",
    "        while not done:\n",
    "            env.render()\n",
    "            state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "            action = agent.choose_action(state)\n",
    "            action = action.cpu().numpy()\n",
    "            print('-----------------')\n",
    "            print(f'action: {action}')\n",
    "            next_state, reward, done, _, _ = env.step(action)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            t += 1\n",
    "            if done or t >= max_t:\n",
    "                break\n",
    "        print(f\"Episode {i_episode}\\tScore: {score}\")\n",
    "\n",
    "        #Final render\n",
    "        env.render()\n",
    "    #env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1 -1 -1 -1]\n",
      "\n",
      "Fitness: -29.400000000000002, Actions left: 70\n",
      "Target Hours:\n",
      "Class 1: [3 4]\n",
      "-----------------\n",
      "action: [0 1 3 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1 -1 -1  0]\n",
      "\n",
      "Fitness: -25.200000000000003, Actions left: 69\n",
      "Target Hours:\n",
      "Class 1: [2 4]\n",
      "-----------------\n",
      "action: [0 1 0 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [ 0 -1 -1  0]\n",
      "\n",
      "Fitness: -21.0, Actions left: 68\n",
      "Target Hours:\n",
      "Class 1: [1 4]\n",
      "-----------------\n",
      "action: [0 0 1 0]\n",
      "Class 1:\n",
      "Day 1: [-1  0 -1 -1]\n",
      "Day 2: [ 0 -1 -1  0]\n",
      "\n",
      "Fitness: -16.8, Actions left: 67\n",
      "Target Hours:\n",
      "Class 1: [0 4]\n",
      "-----------------\n",
      "action: [0 0 0 1]\n",
      "Class 1:\n",
      "Day 1: [ 1  0 -1 -1]\n",
      "Day 2: [ 0 -1 -1  0]\n",
      "\n",
      "Fitness: -12.600000000000001, Actions left: 66\n",
      "Target Hours:\n",
      "Class 1: [0 3]\n",
      "-----------------\n",
      "action: [0 1 3 0]\n",
      "Class 1:\n",
      "Day 1: [ 1  0 -1 -1]\n",
      "Day 2: [ 0 -1 -1 -1]\n",
      "\n",
      "Fitness: -16.8, Actions left: 65\n",
      "Target Hours:\n",
      "Class 1: [1 3]\n",
      "-----------------\n",
      "action: [0 1 3 1]\n",
      "Class 1:\n",
      "Day 1: [ 1  0 -1 -1]\n",
      "Day 2: [ 0 -1 -1  1]\n",
      "\n",
      "Fitness: -12.600000000000001, Actions left: 64\n",
      "Target Hours:\n",
      "Class 1: [1 2]\n",
      "-----------------\n",
      "action: [0 0 2 0]\n",
      "Class 1:\n",
      "Day 1: [ 1  0  0 -1]\n",
      "Day 2: [ 0 -1 -1  1]\n",
      "\n",
      "Fitness: -8.4, Actions left: 63\n",
      "Target Hours:\n",
      "Class 1: [0 2]\n",
      "-----------------\n",
      "action: [0 1 3 0]\n",
      "Class 1:\n",
      "Day 1: [ 1  0  0 -1]\n",
      "Day 2: [ 0 -1 -1 -1]\n",
      "\n",
      "Fitness: -12.600000000000001, Actions left: 62\n",
      "Target Hours:\n",
      "Class 1: [0 3]\n",
      "-----------------\n",
      "action: [0 0 3 0]\n",
      "Class 1:\n",
      "Day 1: [ 1  0  0 -1]\n",
      "Day 2: [ 0 -1 -1 -1]\n",
      "\n",
      "Fitness: -12.600000000000001, Actions left: 61\n",
      "Target Hours:\n",
      "Class 1: [0 3]\n",
      "-----------------\n",
      "action: [0 1 0 1]\n",
      "Class 1:\n",
      "Day 1: [ 1  0  0 -1]\n",
      "Day 2: [-1 -1 -1 -1]\n",
      "\n",
      "Fitness: -16.8, Actions left: 60\n",
      "Target Hours:\n",
      "Class 1: [1 3]\n",
      "-----------------\n",
      "action: [0 0 1 1]\n",
      "Class 1:\n",
      "Day 1: [ 1 -1  0 -1]\n",
      "Day 2: [-1 -1 -1 -1]\n",
      "\n",
      "Fitness: -21.630000000000003, Actions left: 59\n",
      "Target Hours:\n",
      "Class 1: [2 3]\n",
      "-----------------\n",
      "action: [0 1 1 1]\n",
      "Class 1:\n",
      "Day 1: [ 1 -1  0 -1]\n",
      "Day 2: [-1  1 -1 -1]\n",
      "\n",
      "Fitness: -17.430000000000003, Actions left: 58\n",
      "Target Hours:\n",
      "Class 1: [2 2]\n",
      "-----------------\n",
      "action: [0 1 2 0]\n",
      "Class 1:\n",
      "Day 1: [ 1 -1  0 -1]\n",
      "Day 2: [-1  1  0 -1]\n",
      "\n",
      "Fitness: -13.23, Actions left: 57\n",
      "Target Hours:\n",
      "Class 1: [1 2]\n",
      "-----------------\n",
      "action: [0 1 0 1]\n",
      "Class 1:\n",
      "Day 1: [ 1 -1  0 -1]\n",
      "Day 2: [ 1  1  0 -1]\n",
      "\n",
      "Fitness: -9.03, Actions left: 56\n",
      "Target Hours:\n",
      "Class 1: [1 1]\n",
      "-----------------\n",
      "action: [0 0 0 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1  0 -1]\n",
      "Day 2: [ 1  1  0 -1]\n",
      "\n",
      "Fitness: -12.600000000000001, Actions left: 55\n",
      "Target Hours:\n",
      "Class 1: [1 2]\n",
      "-----------------\n",
      "action: [0 1 0 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1  0 -1]\n",
      "Day 2: [-1  1  0 -1]\n",
      "\n",
      "Fitness: -16.8, Actions left: 54\n",
      "Target Hours:\n",
      "Class 1: [1 3]\n",
      "-----------------\n",
      "action: [0 1 1 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1  0 -1]\n",
      "Day 2: [-1 -1  0 -1]\n",
      "\n",
      "Fitness: -21.0, Actions left: 53\n",
      "Target Hours:\n",
      "Class 1: [1 4]\n",
      "-----------------\n",
      "action: [0 0 2 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1 -1  0 -1]\n",
      "\n",
      "Fitness: -25.200000000000003, Actions left: 52\n",
      "Target Hours:\n",
      "Class 1: [2 4]\n",
      "-----------------\n",
      "action: [0 1 2 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1 -1 -1 -1]\n",
      "\n",
      "Fitness: -29.400000000000002, Actions left: 51\n",
      "Target Hours:\n",
      "Class 1: [3 4]\n",
      "-----------------\n",
      "action: [0 0 0 0]\n",
      "Class 1:\n",
      "Day 1: [ 0 -1 -1 -1]\n",
      "Day 2: [-1 -1 -1 -1]\n",
      "\n",
      "Fitness: -25.200000000000003, Actions left: 50\n",
      "Target Hours:\n",
      "Class 1: [2 4]\n",
      "-----------------\n",
      "action: [0 1 3 0]\n",
      "Class 1:\n",
      "Day 1: [ 0 -1 -1 -1]\n",
      "Day 2: [-1 -1 -1  0]\n",
      "\n",
      "Fitness: -21.0, Actions left: 49\n",
      "Target Hours:\n",
      "Class 1: [1 4]\n",
      "-----------------\n",
      "action: [0 0 0 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1 -1 -1  0]\n",
      "\n",
      "Fitness: -25.200000000000003, Actions left: 48\n",
      "Target Hours:\n",
      "Class 1: [2 4]\n",
      "-----------------\n",
      "action: [0 0 3 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1  0]\n",
      "Day 2: [-1 -1 -1  0]\n",
      "\n",
      "Fitness: -21.0, Actions left: 47\n",
      "Target Hours:\n",
      "Class 1: [1 4]\n",
      "-----------------\n",
      "action: [0 1 2 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1  0]\n",
      "Day 2: [-1 -1  0  0]\n",
      "\n",
      "Fitness: -16.8, Actions left: 46\n",
      "Target Hours:\n",
      "Class 1: [0 4]\n",
      "-----------------\n",
      "action: [0 1 1 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1  0]\n",
      "Day 2: [-1  1  0  0]\n",
      "\n",
      "Fitness: -12.600000000000001, Actions left: 45\n",
      "Target Hours:\n",
      "Class 1: [0 3]\n",
      "-----------------\n",
      "action: [0 0 3 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1  1  0  0]\n",
      "\n",
      "Fitness: -16.8, Actions left: 44\n",
      "Target Hours:\n",
      "Class 1: [1 3]\n",
      "-----------------\n",
      "action: [0 1 2 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1  1 -1  0]\n",
      "\n",
      "Fitness: -21.630000000000003, Actions left: 43\n",
      "Target Hours:\n",
      "Class 1: [2 3]\n",
      "-----------------\n",
      "action: [0 0 1 0]\n",
      "Class 1:\n",
      "Day 1: [-1  0 -1 -1]\n",
      "Day 2: [-1  1 -1  0]\n",
      "\n",
      "Fitness: -17.430000000000003, Actions left: 42\n",
      "Target Hours:\n",
      "Class 1: [1 3]\n",
      "-----------------\n",
      "action: [0 1 2 1]\n",
      "Class 1:\n",
      "Day 1: [-1  0 -1 -1]\n",
      "Day 2: [-1  1  1  0]\n",
      "\n",
      "Fitness: -12.600000000000001, Actions left: 41\n",
      "Target Hours:\n",
      "Class 1: [1 2]\n",
      "-----------------\n",
      "action: [0 0 3 0]\n",
      "Class 1:\n",
      "Day 1: [-1  0 -1  0]\n",
      "Day 2: [-1  1  1  0]\n",
      "\n",
      "Fitness: -9.03, Actions left: 40\n",
      "Target Hours:\n",
      "Class 1: [0 2]\n",
      "-----------------\n",
      "action: [0 1 1 1]\n",
      "Class 1:\n",
      "Day 1: [-1  0 -1  0]\n",
      "Day 2: [-1 -1  1  0]\n",
      "\n",
      "Fitness: -13.23, Actions left: 39\n",
      "Target Hours:\n",
      "Class 1: [0 3]\n",
      "-----------------\n",
      "action: [0 0 2 1]\n",
      "Class 1:\n",
      "Day 1: [-1  0  1  0]\n",
      "Day 2: [-1 -1  1  0]\n",
      "\n",
      "Fitness: -8.4, Actions left: 38\n",
      "Target Hours:\n",
      "Class 1: [0 2]\n",
      "-----------------\n",
      "action: [0 1 3 0]\n",
      "Class 1:\n",
      "Day 1: [-1  0  1  0]\n",
      "Day 2: [-1 -1  1 -1]\n",
      "\n",
      "Fitness: -12.600000000000001, Actions left: 37\n",
      "Target Hours:\n",
      "Class 1: [1 2]\n",
      "-----------------\n",
      "action: [0 1 2 0]\n",
      "Class 1:\n",
      "Day 1: [-1  0  1  0]\n",
      "Day 2: [-1 -1 -1 -1]\n",
      "\n",
      "Fitness: -16.8, Actions left: 36\n",
      "Target Hours:\n",
      "Class 1: [1 3]\n",
      "-----------------\n",
      "action: [0 1 3 1]\n",
      "Class 1:\n",
      "Day 1: [-1  0  1  0]\n",
      "Day 2: [-1 -1 -1  1]\n",
      "\n",
      "Fitness: -12.600000000000001, Actions left: 35\n",
      "Target Hours:\n",
      "Class 1: [1 2]\n",
      "-----------------\n",
      "action: [0 0 3 0]\n",
      "Class 1:\n",
      "Day 1: [-1  0  1 -1]\n",
      "Day 2: [-1 -1 -1  1]\n",
      "\n",
      "Fitness: -16.8, Actions left: 34\n",
      "Target Hours:\n",
      "Class 1: [2 2]\n",
      "-----------------\n",
      "action: [0 0 1 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1  1 -1]\n",
      "Day 2: [-1 -1 -1  1]\n",
      "\n",
      "Fitness: -21.0, Actions left: 33\n",
      "Target Hours:\n",
      "Class 1: [3 2]\n",
      "-----------------\n",
      "action: [0 0 2 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1 -1 -1  1]\n",
      "\n",
      "Fitness: -25.200000000000003, Actions left: 32\n",
      "Target Hours:\n",
      "Class 1: [3 3]\n",
      "-----------------\n",
      "action: [0 1 1 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1  1 -1  1]\n",
      "\n",
      "Fitness: -21.630000000000003, Actions left: 31\n",
      "Target Hours:\n",
      "Class 1: [3 2]\n",
      "-----------------\n",
      "action: [0 1 1 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1 -1 -1  1]\n",
      "\n",
      "Fitness: -25.200000000000003, Actions left: 30\n",
      "Target Hours:\n",
      "Class 1: [3 3]\n",
      "-----------------\n",
      "action: [0 1 0 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [ 0 -1 -1  1]\n",
      "\n",
      "Fitness: -21.0, Actions left: 29\n",
      "Target Hours:\n",
      "Class 1: [2 3]\n",
      "-----------------\n",
      "action: [0 1 0 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1 -1 -1  1]\n",
      "\n",
      "Fitness: -25.200000000000003, Actions left: 28\n",
      "Target Hours:\n",
      "Class 1: [3 3]\n",
      "-----------------\n",
      "action: [0 1 0 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [ 1 -1 -1  1]\n",
      "\n",
      "Fitness: -21.0, Actions left: 27\n",
      "Target Hours:\n",
      "Class 1: [3 2]\n",
      "-----------------\n",
      "action: [0 1 1 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [ 1  0 -1  1]\n",
      "\n",
      "Fitness: -17.430000000000003, Actions left: 26\n",
      "Target Hours:\n",
      "Class 1: [2 2]\n",
      "-----------------\n",
      "action: [0 1 0 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1  0 -1  1]\n",
      "\n",
      "Fitness: -21.630000000000003, Actions left: 25\n",
      "Target Hours:\n",
      "Class 1: [2 3]\n",
      "-----------------\n",
      "action: [0 1 1 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [-1 -1 -1  1]\n",
      "\n",
      "Fitness: -25.200000000000003, Actions left: 24\n",
      "Target Hours:\n",
      "Class 1: [3 3]\n",
      "-----------------\n",
      "action: [0 0 2 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1  0 -1]\n",
      "Day 2: [-1 -1 -1  1]\n",
      "\n",
      "Fitness: -21.0, Actions left: 23\n",
      "Target Hours:\n",
      "Class 1: [2 3]\n",
      "-----------------\n",
      "action: [0 1 2 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1  0 -1]\n",
      "Day 2: [-1 -1  1  1]\n",
      "\n",
      "Fitness: -16.8, Actions left: 22\n",
      "Target Hours:\n",
      "Class 1: [2 2]\n",
      "-----------------\n",
      "action: [0 1 0 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1  0 -1]\n",
      "Day 2: [ 1 -1  1  1]\n",
      "\n",
      "Fitness: -13.23, Actions left: 21\n",
      "Target Hours:\n",
      "Class 1: [2 1]\n",
      "-----------------\n",
      "action: [0 0 0 0]\n",
      "Class 1:\n",
      "Day 1: [ 0 -1  0 -1]\n",
      "Day 2: [ 1 -1  1  1]\n",
      "\n",
      "Fitness: -9.66, Actions left: 20\n",
      "Target Hours:\n",
      "Class 1: [1 1]\n",
      "-----------------\n",
      "action: [0 0 0 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1  0 -1]\n",
      "Day 2: [ 1 -1  1  1]\n",
      "\n",
      "Fitness: -13.23, Actions left: 19\n",
      "Target Hours:\n",
      "Class 1: [2 1]\n",
      "-----------------\n",
      "action: [0 0 2 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [ 1 -1  1  1]\n",
      "\n",
      "Fitness: -17.430000000000003, Actions left: 18\n",
      "Target Hours:\n",
      "Class 1: [3 1]\n",
      "-----------------\n",
      "action: [0 1 2 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [ 1 -1 -1  1]\n",
      "\n",
      "Fitness: -21.0, Actions left: 17\n",
      "Target Hours:\n",
      "Class 1: [3 2]\n",
      "-----------------\n",
      "action: [0 1 2 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [ 1 -1  1  1]\n",
      "\n",
      "Fitness: -17.430000000000003, Actions left: 16\n",
      "Target Hours:\n",
      "Class 1: [3 1]\n",
      "-----------------\n",
      "action: [0 0 0 0]\n",
      "Class 1:\n",
      "Day 1: [ 0 -1 -1 -1]\n",
      "Day 2: [ 1 -1  1  1]\n",
      "\n",
      "Fitness: -13.23, Actions left: 15\n",
      "Target Hours:\n",
      "Class 1: [2 1]\n",
      "-----------------\n",
      "action: [0 0 2 0]\n",
      "Class 1:\n",
      "Day 1: [ 0 -1  0 -1]\n",
      "Day 2: [ 1 -1  1  1]\n",
      "\n",
      "Fitness: -9.66, Actions left: 14\n",
      "Target Hours:\n",
      "Class 1: [1 1]\n",
      "-----------------\n",
      "action: [0 0 0 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1  0 -1]\n",
      "Day 2: [ 1 -1  1  1]\n",
      "\n",
      "Fitness: -13.23, Actions left: 13\n",
      "Target Hours:\n",
      "Class 1: [2 1]\n",
      "-----------------\n",
      "action: [0 0 2 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [ 1 -1  1  1]\n",
      "\n",
      "Fitness: -17.430000000000003, Actions left: 12\n",
      "Target Hours:\n",
      "Class 1: [3 1]\n",
      "-----------------\n",
      "action: [0 1 3 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [ 1 -1  1 -1]\n",
      "\n",
      "Fitness: -21.630000000000003, Actions left: 11\n",
      "Target Hours:\n",
      "Class 1: [3 2]\n",
      "-----------------\n",
      "action: [0 0 2 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1  1 -1]\n",
      "Day 2: [ 1 -1  1 -1]\n",
      "\n",
      "Fitness: -17.430000000000003, Actions left: 10\n",
      "Target Hours:\n",
      "Class 1: [3 1]\n",
      "-----------------\n",
      "action: [0 0 2 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1 -1]\n",
      "Day 2: [ 1 -1  1 -1]\n",
      "\n",
      "Fitness: -21.630000000000003, Actions left: 9\n",
      "Target Hours:\n",
      "Class 1: [3 2]\n",
      "-----------------\n",
      "action: [0 0 3 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1  0]\n",
      "Day 2: [ 1 -1  1 -1]\n",
      "\n",
      "Fitness: -17.430000000000003, Actions left: 8\n",
      "Target Hours:\n",
      "Class 1: [2 2]\n",
      "-----------------\n",
      "action: [0 1 1 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1  0]\n",
      "Day 2: [ 1  1  1 -1]\n",
      "\n",
      "Fitness: -12.600000000000001, Actions left: 7\n",
      "Target Hours:\n",
      "Class 1: [2 1]\n",
      "-----------------\n",
      "action: [0 1 2 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1  0]\n",
      "Day 2: [ 1  1 -1 -1]\n",
      "\n",
      "Fitness: -16.8, Actions left: 6\n",
      "Target Hours:\n",
      "Class 1: [2 2]\n",
      "-----------------\n",
      "action: [0 1 1 0]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1  0]\n",
      "Day 2: [ 1 -1 -1 -1]\n",
      "\n",
      "Fitness: -21.0, Actions left: 5\n",
      "Target Hours:\n",
      "Class 1: [2 3]\n",
      "-----------------\n",
      "action: [0 1 1 1]\n",
      "Class 1:\n",
      "Day 1: [-1 -1 -1  0]\n",
      "Day 2: [ 1  1 -1 -1]\n",
      "\n",
      "Fitness: -16.8, Actions left: 4\n",
      "Target Hours:\n",
      "Class 1: [2 2]\n",
      "-----------------\n",
      "action: [0 0 0 1]\n",
      "Class 1:\n",
      "Day 1: [ 1 -1 -1  0]\n",
      "Day 2: [ 1  1 -1 -1]\n",
      "\n",
      "Fitness: -12.600000000000001, Actions left: 3\n",
      "Target Hours:\n",
      "Class 1: [2 1]\n",
      "-----------------\n",
      "action: [0 0 2 1]\n",
      "Class 1:\n",
      "Day 1: [ 1 -1  1  0]\n",
      "Day 2: [ 1  1 -1 -1]\n",
      "\n",
      "Fitness: -9.03, Actions left: 2\n",
      "Target Hours:\n",
      "Class 1: [2 0]\n",
      "-----------------\n",
      "action: [0 1 0 0]\n",
      "Class 1:\n",
      "Day 1: [ 1 -1  1  0]\n",
      "Day 2: [-1  1 -1 -1]\n",
      "\n",
      "Fitness: -13.23, Actions left: 1\n",
      "Target Hours:\n",
      "Class 1: [2 1]\n",
      "-----------------\n",
      "action: [0 1 0 1]\n",
      "Episode 1\tScore: -3.7342857142857144\n",
      "Class 1:\n",
      "Day 1: [ 1 -1  1  0]\n",
      "Day 2: [ 1  1 -1 -1]\n",
      "\n",
      "Fitness: -9.03, Actions left: 0\n",
      "Target Hours:\n",
      "Class 1: [2 0]\n"
     ]
    }
   ],
   "source": [
    "visualize_actor_critic_agent(agent, env,n_episodes=1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
